{
  "hidden_dim": 128,
  "num_heads": 8,
  "num_lstm_layers": 1,
  "dropout_rate": 0.3,
  "learning_rate": 0.001,
  "batch_size": 32,
  "max_epochs": 100,
  "patience": 15
}